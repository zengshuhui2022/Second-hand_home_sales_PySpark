{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bfdb245",
   "metadata": {},
   "source": [
    "爬取链家网站上武汉市二手房销售数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a84607de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d84ab312",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list=[]           # 用于存储一个页面下的房产的相关数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b64ed115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_page(url):                    \n",
    "    # 定义函数：打开网页，并该爬取网页的源代码\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.75 Safari/537.36 Edg/86.0.622.38'}\n",
    "    req = requests.get(url,headers=headers)\n",
    "    req.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(req.text,'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f917fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data_list):\n",
    "    data=pd.DataFrame(data_list)\n",
    "    # 定义函数：用于将所爬取到的数据存储为csv文件\n",
    "    if not os.path.exists(\"./data/武汉二手房.csv\"):          # 若文件不存在，则创建新文件，此时要有表头\n",
    "        data.to_csv(\"./data/武汉二手房.csv\",encoding='ANSI',mode='a+',index=False)\n",
    "    else:                                                    # 若文件已经存在，则将数据追加到该文件中，此时不加表头\n",
    "        data.to_csv(\"./data/武汉二手房.csv\",encoding='ANSI',mode='a+',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9515aecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_one_page(soup):                   \n",
    "    # 定义函数：提取网页源代码中的有效信息\n",
    "    try:       # 如果能够成功解析数据，就将数据存储到文件中\n",
    "        items_list=soup.select('div[class=\"property-content\"]')     # 返回一个列表，列表中的元素是每一个房子所对应的标签\n",
    "        # 解析并存储每个房产中所要提取的特征\n",
    "        for i in range(len(items_list)):\n",
    "            # 解析\n",
    "            item=items_list[i]\n",
    "            title=item.h3.string           # 标题\n",
    "            stru=item.select('p[class=\"property-content-info-text property-content-info-attribute\"] span')    # 室厅卫\n",
    "            num_s=stru[0].string           # 室数\n",
    "            num_t=stru[2].string           # 厅数\n",
    "            num_w=stru[4].string           # 卫数\n",
    "            info=item.select('p[class=\"property-content-info-text\"]')            \n",
    "            pattern=re.compile(\"\\S.*\")\n",
    "            surface=pattern.search(info[0].string).group()            # 面积\n",
    "            direction=pattern.search(info[1].string).group()          # 朝向\n",
    "            neighbor=item.select('p[class=\"property-content-info-comm-name\"]')[0].string               # 小区\n",
    "            location1=item.select('p[class=\"property-content-info-comm-address\"] span')[0].string      # 行政区\n",
    "            location2=item.select('p[class=\"property-content-info-comm-address\"] span')[1].string      # 所属街道\n",
    "            location3=item.select('p[class=\"property-content-info-comm-address\"] span')[2].string      # 具体门牌号\n",
    "            total_price=item.select('p[class=\"property-price-total\"] span')[0].string+item.select('p[class=\"property-price-total\"] span')[1].string    # 房屋总价\n",
    "            average_price=item.select('p[class=\"property-price-average\"]')[0].string      # 房屋单价\n",
    "            # 注意到有些房产中没有楼层数和建造时间的相关信息，所以在此需要进行异常处理\n",
    "            try:\n",
    "                floors=pattern.search(info[2].string).group()             # 楼层数\n",
    "                year=pattern.search(info[3].string).group()               # 建造时间\n",
    "            except Exception as ex:\n",
    "                floors=None\n",
    "                year=None\n",
    "            # 将零散数据整合到字典中\n",
    "            data_dict={}\n",
    "            data_dict[\"标题\"]=title\n",
    "            data_dict[\"室数\"]=num_s\n",
    "            data_dict[\"厅数\"]=num_t\n",
    "            data_dict[\"卫数\"]=num_w\n",
    "            data_dict[\"面积\"]=surface\n",
    "            data_dict[\"朝向\"]=direction\n",
    "            data_dict[\"楼层数\"]=floors\n",
    "            data_dict[\"建造时间\"]=year\n",
    "            data_dict[\"小区\"]=neighbor\n",
    "            data_dict[\"行政区\"]=location1\n",
    "            data_dict[\"街道\"]=location2\n",
    "            data_dict[\"门牌号\"]=location3\n",
    "            data_dict[\"单价\"]=average_price\n",
    "            data_dict[\"总价\"]=total_price\n",
    "            # 将该房产的相关数据构成的字典，追加到data_list列表中\n",
    "            data_list.append(data_dict)\n",
    "            pass\n",
    "        save_data(data_list)\n",
    "        print('已经成功爬取并保存')\n",
    "    except Exception as ex:      # 如果解析出错，则打印错误信息\n",
    "        print('出现错误，错误信息为：',ex)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1e66374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunSpider(offset):                        # 定义执行函数\n",
    "    url=\"https://wuhan.anjuke.com/sale/p{}/\".format(offset)\n",
    "    # 开始发起请求\n",
    "    resultHtml=get_one_page(url)              # 获取该网页上的源代码信息\n",
    "    # 解析并存储数据\n",
    "    result=parse_one_page(resultHtml)         # 解析该页面数据，解析成功则保存，解析失败则打印错误信息\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcb1fdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第2页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第3页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第4页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第5页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第6页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第7页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第8页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第9页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第10页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第11页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第12页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第13页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第14页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第15页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第16页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第17页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第18页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第19页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第20页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第21页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第22页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第23页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第24页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第25页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第26页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第27页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第28页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第29页数据的爬取情况：\n",
      "已经成功爬取并保存\n",
      "第30页数据的爬取情况：\n",
      "已经成功爬取并保存\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,31):         \n",
    "    print(f'第{i}页数据的爬取情况：')\n",
    "    RunSpider(i)\n",
    "    # 添加一个延时的等待 防止速度过快被反爬\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c999c58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
